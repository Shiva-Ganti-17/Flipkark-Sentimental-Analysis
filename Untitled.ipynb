{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f81ca25-5014-4665-acce-2cc6ab43ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/reviews_data_dump/reviews_badminton/data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3586549f-5fb0-44a5-ad2e-6dc53b158504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb-21</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb-21</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr-21</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr-16</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes   Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb-21   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb-21   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr-21   \n",
       "3     Certified Buyer, Chennai      25.0         1.0     NaN   \n",
       "4                          NaN     147.0        24.0  Apr-16   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb5afd2-5b17-43ab-a35b-ed272a30729f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reviewer Name Review Title Place of Review  Up Votes  Down Votes Month  \\\n",
       "8513           NaN          NaN             NaN       NaN         NaN   NaN   \n",
       "8514           NaN          NaN             NaN       NaN         NaN   NaN   \n",
       "8515           NaN          NaN             NaN       NaN         NaN   NaN   \n",
       "8516           NaN          NaN             NaN       NaN         NaN   NaN   \n",
       "8517           NaN          NaN             NaN       NaN         NaN   NaN   \n",
       "\n",
       "     Review text  Ratings  \n",
       "8513         NaN        5  \n",
       "8514         NaN        2  \n",
       "8515         NaN        4  \n",
       "8516         NaN        1  \n",
       "8517         NaN        4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20463987-7675-4122-9be9-77ec0c9eb857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8518, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69bda7e-e5b6-4704-930a-8fa56569f2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name       10\n",
       "Review Title        10\n",
       "Place of Review     50\n",
       "Up Votes            10\n",
       "Down Votes          10\n",
       "Month              465\n",
       "Review text          8\n",
       "Ratings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df9a806-99bd-4fb3-ad1e-e0e6676a0c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_16068\\3752391776.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Review text'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Review text'].fillna('', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fccfde-53ee-49da-bdf5-8006e2240476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\shiva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Review text  Sentiment\n",
      "0  Nice product, good quality, but price is now r...          1\n",
      "1  They didn't supplied Yonex Mavis 350. Outside ...          0\n",
      "2  Worst product. Damaged shuttlecocks packed in ...          0\n",
      "3  Quite O. K. , but nowadays  the quality of the...          1\n",
      "4  Over pricedJust â?¹620 ..from retailer.I didn'...          1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#Download NLTK resources (if not already downloaded)\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# Function to analyze the sentiment of each review text and return binary classification\n",
    "def analyze_sentiment_binary(review_text):\n",
    "   \n",
    "    # Tokenize text into sentences\n",
    "    sentences = nltk.sent_tokenize(review_text)\n",
    "    \n",
    "    # Check if there are no sentences\n",
    "    if not sentences:\n",
    "        return 0  # Neutral sentiment\n",
    "    \n",
    "    # Initialize sentiment scores\n",
    "    compound_score = 0\n",
    "    \n",
    "    # Get sentiment score for each sentence and aggregate\n",
    "    for sentence in sentences:\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        compound_score += ss['compound']\n",
    "    \n",
    "    # Normalize compound score\n",
    "    normalized_score = compound_score / len(sentences)\n",
    "    \n",
    "    # Classify sentiment as binary\n",
    "    if normalized_score >= 0:\n",
    "        return 1  # Positive sentiment\n",
    "    else:\n",
    "        return 0  # Negative sentiment\n",
    "\n",
    "# Apply sentiment analysis to each review text and add 'Sentiment' column\n",
    "df['Sentiment'] = df['Review text'].apply(analyze_sentiment_binary)\n",
    "\n",
    "# Display the first few rows with sentiment analysis results\n",
    "print(df[['Review text', 'Sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6e339a-2173-4ea4-a896-52b2a8f55bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6814,) (1704,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Review text'], df['Sentiment'], test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aff119c-bae4-4ec6-809f-fd1e6be61243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Removing special characters and digits\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # Change text to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize into words\n",
    "    tokens = text.split()\n",
    "    # Remove stop words                \n",
    "    clean_tokens = [t for t in tokens if not t in stopwords.words(\"english\")]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "    return \" \".join(clean_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6b221d-98a0-457f-ae04-c1eb2ada8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = X_train.apply(preprocess_text)\n",
    "X_test_processed = X_test.apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5b4f9c1-d8f7-4658-a953-e50666933941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 18:27:18 INFO mlflow.tracking.fluent: Experiment with name 'Sentiment_Analysis' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/shiva/OneDrive/Desktop/innomatics%20research%20labs/Flipkart/experiment%20tracking/mlruns/324248996580998105', creation_time=1711630638664, experiment_id='324248996580998105', last_update_time=1711630638664, lifecycle_stage='active', name='Sentiment_Analysis', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Sentiment_Analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd86ebf9-0014-405b-9bcc-d56eecb9b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "from joblib import Memory\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define a memory object to cache intermediate results\n",
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "# Define pipelines for different classifiers\n",
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ]),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'random_forest': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'svm': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ]),\n",
    "    'knn': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define parameter grids for hyperparameter tuning\n",
    "param_grids = {\n",
    "    'naive_bayes': {\n",
    "        'vectorization__max_features': [1000, 1500, 2000, 5000],\n",
    "        'classifier__alpha': [1, 10]\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'vectorization__max_features': [1000, 1500, 2000, 5000],\n",
    "        'classifier__max_depth': [None, 5, 10]\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'vectorization__max_features': [1000, 1500, 2000, 5000],\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 5, 10]\n",
    "    },\n",
    "    'svm': {\n",
    "        'vectorization__max_features': [1000, 1500, 2000, 5000],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'knn': {\n",
    "        'vectorization__max_features': [1000, 1500, 2000, 5000],\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'vectorization__max_features': [1000, 1500, 2000, 5000],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__solver': ['lbfgs', 'liblinear']\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e60c6175-46f8-44b3-ac1d-db37698ed3a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Review text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:175\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Review text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert series to dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_features \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReview text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert target labels to array\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_train_labels \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1112\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1228\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1228\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Review text'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b040d6a-ed9f-4bd1-aa42-5d030b01f13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
